# Landmark Segmentation with Foundation Models

This repository contains a simplified and anonymized preview of a work-in-progress project under AAAI 2026 submission.

** Full code and data will be released upon acceptance.

## Description
We explore the adaptation of vision foundation models (e.g. SAM2, Depth Anything V2) for depth-aware landmark segmentation in laparoscopic imagery.

### ✅ Features shown
- Mock RGB & depth fusion data pipeline
- Inference pipeline using pretrained SAM2 (no fine-tuned weights)
- Visualization of contour extraction

### ❌ Not included
- Custom fusion architecture details
- Fine-tuning scripts or training data
- Real surgical images

** For code access under NDA or interview context, please contact: `lyunchen178@gmail.com`
